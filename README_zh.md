**其他语言版本：[English](README.md)，[中文](README_zh.md).**

# 3维注意力多尺度训练网络(TDMTNet)
在手写文本识别任务中, 隐马尔可夫模型(HMM)通过使用多个状态对每个字符进行较高分辨率的建模。然而，它需要复杂的训练与推理流程，包括特征设计，生成式模型混合高斯-隐马尔可夫模型(GMM-HMM)，区分式模型神经网络-隐马尔可夫模型(NN-HMM)以及语言模型。基于连接时序分类(CTC)与编解码(Encoder-Decoder)的方法使用更高效与直接的数学计算，相应的网络能够被端到端的训练。与HMM相比较，他们对每个字符的建模分辨率相对较低。当被用到长的手写文本识别任务上时，识别网络可能会产生注意力漂移的问题。之前的实验表明他们需要更多的训练文本。

受典型无显示分割方法(HMM、CTC、ED)的启发，我们设计了一种能够吸收三种无显示分割方法优点的神经网络。它的结构如下面图片所示，它具有四个特征：

(1)包含混合注意力模块的卷积神经网络前端；(2)三维(3D)注意力模块；(3)特征融合模块；(4)多尺度训练。
![](https://github.com/Wukong90/3DAttentionMultiScaleTraining-for-HTR/blob/main/imgs/diff_methods.png)

下图显示了提出的多尺度训练方法，其中虚线内的部分只在训练中被使用。多尺度训练包括两部分。首先，在训练阶段，多个不同帧长的特征序列被同时提取。虽然包含有相同的3D注意力模块与全局-局部上下文特征被使用，在推理阶段，我们仅仅只保留对应帧长为3的网络分支。其次，我们使用CTC与交叉熵(CE)损失进行联合优化。
![](https://github.com/Wukong90/3DAttentionMultiScaleTraining-for-HTR/blob/main/imgs/net_structure.png)

# 代码与训练权重

针对手写文本行识别的TDMTNet代码以及训练、测试代码已经开源(交叉熵损失辅助微调的代码暂未公布)。中文数据集的训练/测试代码为train_TDMSNet_Chinese.py，英文数据集的训练/测试代码为train_TDMSNet_eng.py。网络模型位于model/model.py中，configure中包含主要的配置文件、参数设置以及数据集构建与图像预处理代码，目录Datasets_list用于存放训练/测试图像数据以及文件名列表，目录weights中保存有我们在不同数据集中训练好的网络权重，名称中只含有CTC的目录表示该权重未经过CE损失微调，名称中包含CTC_CE表示网络权重经过CE微调。且它们包含有三个完整的分支。推理阶段，我们其实仅仅需要保留窗长长度为3所对应的分支。

# 实验数据集

所提出的网络在两个具有挑战的最新中文手写文本数据集（SCUT-HCCDoc和SCUT-EPT）和一个重要的英文手写文本数据集IAM中进行验证。 

在SCUT-HCCDoc数据集中，原始训练集包含文本行图像93,254幅，1,993张低质量（文字难以辨认、胡乱涂鸦、文字背景高度重叠以及字符不全）与竖直方向书写的图像被删除。因此实验中只使用了91,261张文本行图像用于网络训练。目录
Datasets_list/SCUT-HCCDoc/中train_list.txt与test_list.txt为我们使用的训练图像列表与测试图像列表，测试集包含了该数据集的原始全部测试图片。需要注意的是，该数据集的创建者只提供了篇章级文字图片以及它们中包含的文本行标注(json文件)，我们的列表中所列为文本行图像名，文本行的命名方式为 它所属于的原始篇章级图片名_它所在的行序号，行序号按照原始json文件中的文本行顺序。目录Datasets_list/SCUT-HCCDoc/abnormal_lists_and_images中是被排除的原始训练集中的低质量或竖直方向书写的手写文本图像。所有异常图像在abnormals目录中,all_abnormal_list.txt为所有异常图像列表，*_abnormal.txt为对应子集的异常文本图像名列表，*为原始数据子集的名称。

Datasets_list/SCUT-HCCDoc下的文件TrainDataRuChar2Int_HCCDoc.npy 与 TrainDataRuInt2Char_HCCDoc.npy 保存有我们在实验中使用的该数据集的字符与网络输出节点对应关系。

在SCUT-EPT数据集中，681张包含有字符交换或重叠的异常手写文本被删除，实际只使用39,319副文本行图像用于训练。Datasets_list/SCUT-EPT/中的train_list.txt与test_list.txt为我们使用的训练图像列表与测试图像列表，测试
集包含了该数据集的原始全部测试图像。abnormal.txt为训练集中被排除的681张异常图片列表，它们的具体分类可以另外参考我们的项目https://github.com/Wukong90/EHT-Dataset.SCUT-EPT-Abnormal 。

Datasets_list/SCUT-EPT/下的文件TrainDataRuChar2Int_EPT.npy 与 TrainDataRuInt2Char_EPT.npy 保存有我们在实验中使用的该数据集的字符与网络输出节点对应关系。

标准的IAM数据集提供了一个训练集、两个验证集和一个测试集。目录Datasets_list/IAM/split/中列出的trainset.txt、validationset1.txt、validationset2.txt、testset.txt为相应的训练列表、验证列表与测试列表。我们的实验中使用了原始的全部训练数据作为网络训练，两个验证集全部数据用于选择最好模型进行测试集上的评估，标准测试集中的所有图片都被用于评估模型的最终性能。

两个较新的具有挑战的手写中文数据集SCUT-HCCDoc和SCUT-EPT可以分别从https://github.com/HCIILAB/SCUT-HCCDoc_Dataset_Release 与 https://github.com/HCIILAB/SCUT-EPT_Dataset_Release?tab=readme-ov-file 申请获得。手写英文数据集IAM可以从https://fki.tic.heia-fr.ch/databases/iam-handwriting-database 获得，需要注意的是自从2018年后，大多数相关研究者的工作采用了所谓的RWTH数据划分方式，它们与标准的IAM数据集划分并不相同。
